# Vanilla Implementation

This repository holds an implementation of the **Vanilla Transformer** detailed in the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762).

The philosophy behind this repository is similar to that of Richard Feynman's philosophy to learning -- you don't fully understand something unless you can explain it in simple terms to a non-expert. Implementing a transformer using nothing but [NumPY](https://numpy.org/) and rudimentary [PyTorch](https://pytorch.org/) building blocks will (hopefully) meet this end.
